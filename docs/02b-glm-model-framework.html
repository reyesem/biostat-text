<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Modeling for the Biological Sciences - 4&nbsp; General Linear Model Framework</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02c-glm-assessing-conditions.html" rel="next">
<link href="./02a-glm.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="mystyles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02a-glm.html">Unit II: General Linear Model</a></li><li class="breadcrumb-item"><a href="./02b-glm-model-framework.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">General Linear Model Framework</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Biostatistics</a> 
        <div class="sidebar-tools-main">
    <a href="./ma482-text.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01a-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit I: Review of Statistics and Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01b-statistical-process.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Overview of the Statistical Process</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01c-distributional-quartet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributional Quartet</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01d-essential-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Essential Probability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02a-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit II: General Linear Model</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02b-glm-model-framework.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">General Linear Model Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02c-glm-assessing-conditions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Assessing the Conditions for the General Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02d-glm-unifying-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The General Linear Model as a Unifying Framework</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03a-modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit III: General Modeling Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03b-modeling-related-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addressing Relationships Between Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03c-modeling-categorical-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Incorporating Categorical Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03d-modeling-interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Allowing Effect Modification (Interaction Terms)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03e-modeling-linear-hypotheses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">General Linear Hypothesis Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03f-modeling-large-sample-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Large Sample Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03g-modeling-splines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Modeling Curvature (Splines)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04a-rm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit IV: Models for Repeated Measures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04b-rm-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">The Language of Repeated Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04c-rm-mixed-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixed Effects Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04d-rm-gee.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Generalized Estimating Equations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#parameter-estimation" id="toc-parameter-estimation" class="nav-link active" data-scroll-target="#parameter-estimation"><span class="header-section-number">4.1</span> Parameter Estimation</a></li>
  <li><a href="#conditions-on-the-model" id="toc-conditions-on-the-model" class="nav-link" data-scroll-target="#conditions-on-the-model"><span class="header-section-number">4.2</span> Conditions on the Model</a></li>
  <li><a href="#alternate-characterization-of-the-model" id="toc-alternate-characterization-of-the-model" class="nav-link" data-scroll-target="#alternate-characterization-of-the-model"><span class="header-section-number">4.3</span> Alternate Characterization of the Model</a></li>
  <li><a href="#interpretation-of-parameters" id="toc-interpretation-of-parameters" class="nav-link" data-scroll-target="#interpretation-of-parameters"><span class="header-section-number">4.4</span> Interpretation of Parameters</a></li>
  <li><a href="#inference-about-the-mean-parameters" id="toc-inference-about-the-mean-parameters" class="nav-link" data-scroll-target="#inference-about-the-mean-parameters"><span class="header-section-number">4.5</span> Inference About the Mean Parameters</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-glm-model-framework" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">General Linear Model Framework</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The most interesting scientific questions involve characterizing the relationship between a response and some predictor. And, we know that these relationships do not exist in a vacuum. The response we observe is typically the result of a complex data generating process involving several potential predictors (or features/characteristics) of the subjects in the population. In order to incorporate these additional features, we need <em>multivariable</em> models.</p>
<p>The development of a model should not be divorced from its intended use, and in general, there are three uses for multivariable models. That is, the majority of scientific questions can be categorized into one of three groups: prediction, isolating an effect, or studying the interplay between variables.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are primarily three uses for a multivariable model</p>
<ul>
<li><strong>Prediction</strong>: modeling a relationship for the purpose of estimating a future occurrence given new data.</li>
<li><strong>Isolating an Effect</strong>: describing the relationship between a response and predictor after accounting for the influence of other predictors measured.</li>
<li><strong>Studying the Interplay</strong>: examining how the relationship of two variables is impacted by the value of a third variable.</li>
</ul>
</div>
</div>
<p>While we introduce these elements in the context of the general linear model, note that these uses carry over into other regression models we will examine.</p>
<p>Consider a gardener studying two common organic fertilizers. She could have the following questions in mind:</p>
<ol type="A">
<li>What do I anticipate the yield of tomatoes to be next summer when using cow manure?</li>
<li>Does bat guano tend to result in higher tomato yields compared with cow manure after accounting for any impact on yield that results from the amount of water the plants receive?</li>
<li>Does the efficacy of bat guano (compared with cow manure) depend on the amount of sunlight the plants receive?</li>
</ol>
<p>The first question is an example of prediction; given the fertilizer applied (as well as potentially other characteristics of the garden), what does she expect the results to be in the future? The second question examines the impact (or effect) of the fertilizer <em>above and beyond</em> any impact of watering; she is interested in <em>isolating</em> the effect of fertilizer from the effect of watering. In the last question, she is not only interested in the effect of the fertilizer on the yield, but she wants to acknowledge that this impact could depend on a third variable (sunlight); for example, bat guano may be superior under low light settings but inferior under lots of sunlight. This is an example of the interplay between the fertilizer and the sunlight.</p>
<p>In each of these objectives, there are multiple things at play, requiring modeling techniques that account for multiple predictors simultaneously. The general linear model views the response as a being the result of a linear combination of several variables; our measurement of this linear combination is then subject to error. Specifically, the framework generalizes the simple linear regression model studied in introductory statistics to characterize the average response as a function of several variables simultaneously.</p>
<div id="def-general-linear-model" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.1 (General Linear Model) </strong></span>The general linear model views the response (outcome) as a linear combination of several predictors:</p>
<p><span class="math display">\[
\begin{aligned}
  (\text{Response})_i
    &amp;= \beta_0 + \beta_1 (\text{Predictor 1})_{i} + \beta_2 (\text{Predictor 2})_{i} + \dotsb +
      \beta_p (\text{Predictor } p)_{i} + \varepsilon_i \\
    &amp;= \beta_0 + \sum\limits_{j=1}^{p} \beta_j (\text{Predictor } j)_{i} + \varepsilon_i
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of subjects in the sample, <span class="math inline">\(p &lt; n\)</span> is the number of predictors in the model, and <span class="math inline">\(\varepsilon_i\)</span> is a random variable that captures the error in the response.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Many texts use <span class="math inline">\(y_i\)</span> to denote the response of the <span class="math inline">\(i\)</span>-th observation and <span class="math inline">\(x_{j,i}\)</span> to denote the value of the <span class="math inline">\(j\)</span>-th predictor for the <span class="math inline">\(i\)</span>-th subject, resulting in the general linear model having the form</p>
<p><span class="math display">\[y_i = \beta_0 + \sum\limits_{j=1}^{p} \beta_j x_{j, i} + \varepsilon_i.\]</span></p>
<p>This notation is helpful when discussing the underlying mathematics, but we prefer being more explicit in identifying the response and predictors when discussing the model itself.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some disciplines refer to the response/outcome as the “dependent variable” and the predictors as “independent variables,” but we find this language a bit dated.</p>
<p>We will use the terms “predictor” and “covariate” interchangeably, while some disciplines distinguish between categorical predictors as factors and continuous predictors as covariates (variables that “co-vary” with the factor of interest).</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>While not a theoretical requirement, we will only consider the case where <span class="math inline">\(p &lt; n\)</span>, which is common in many disciplines. One discipline in which this is often not valid is genetics. Special methods are required in such “high dimensional” settings that are beyond the scope of this text.</p>
</div>
</div>
<p>The general linear model has two distinct components — a deterministic component (the linear combination of the predictors) and a stochastic component (the error term). We can think of the error term as the “junk drawer” for the model, capturing anything not explained by the deterministic portion of the model. The error could include systematic error in measuring the response, biological error contributing to the fact that two subjects with the same values of the predictors have different responses, etc.<br>
:::{.callout-caution} We stress that <a href="#def-general-linear-model">Definition&nbsp;<span>4.1</span></a> is a <em>model</em>. Like all models, it is a simple representation of a complex process. It is something we posit characterizes the underlying data generating process. :::</p>
<p>The key feature of this model is that it relates the response to several predictors <em>simultaneously</em>. However, this model is currently comprised of unknown parameters (the coefficients <span class="math inline">\(\beta_1, \beta_2, \dotsc, \beta_p\)</span>). For it to be useful in practice, we need estimates of these parameters.</p>
<section id="parameter-estimation" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="parameter-estimation"><span class="header-section-number">4.1</span> Parameter Estimation</h2>
<p>The coefficients in front of each predictor act as parameters in the model, as they are unknown and characterize the distribution of the response in some way. Our goal is to construct estimates of these unknown quantities. The most common method of estimation is the method of least squares.</p>
<div id="def-least-squares" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.2 (Least Squares Estimation) </strong></span>The method of least squares may be used to estimate the coefficients (parameters) of a linear model. In particular, we choose the values of the coefficients that minimize</p>
<p><span class="math display">\[\sum\limits_{i=1}^{n} \left((\text{Response})_i - \beta_0 - \sum\limits_{j=1}^{p} \beta_j (\text{Predictor } j)_{i}\right)^2.\]</span></p>
<p>The resulting “least squares” estimates are denoted <span class="math inline">\(\widehat{\beta}_0, \widehat{\beta}_1, \dotsc, \widehat{\beta}_p\)</span>.</p>
</div>
<p>It is important to remember that the method of least squares results in <em>estimates</em> of the parameters. We are not “solving” for the parameters; the parameters will always remain unknown quantities. We are using data to estimate the parameters. There is really nothing statistical about least squares. It is simply an optimization problem — choosing coefficients to minimize some criteria. Of course, we do not determine these estimates by hand; instead, we rely on statistical software.</p>
<p>We cannot stress enough that the act of obtaining these estimates is simply an optimization exercise. While a computer can provide these estimates, we cannot yet even interpret these estimates without further assumptions on the model. This is where it becomes a <em>statistical</em> problem — specifying the conditions required for the purpose of making inference on the unknown parameters.</p>
</section>
<section id="conditions-on-the-model" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="conditions-on-the-model"><span class="header-section-number">4.2</span> Conditions on the Model</h2>
<p>The act of estimation alone is really a mathematical problem. Being able to describe the properties of those estimates, quantify the variability in those estimates, and use those estimates to make inference on the population parameters is where we enter statistics. Whenever a random variable is present in a model, inference requires us to make assumptions about its underlying distribution. As analysts, we balance making inference easy mathematically by making more assumptions (adding more structure to the model) and making the model more flexible (not making the model too restrictive).</p>
<p>Most software, by default, places four conditions on the distribution of the error term in the model. We refer to this collection of conditions as the “classical regression model.”</p>
<div id="def-classical-regression" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.3 (Classical Regression Model) </strong></span>In the “classical regression model,” we place the following four conditions on the distribution of the error <span class="math inline">\(\varepsilon_i\)</span>:</p>
<ol type="1">
<li>The average error across all levels of the predictors is 0; mathematically, we write <span class="math inline">\(E\left(\varepsilon_i \mid (\text{Predictors 1 - }p)_i\right) = 0\)</span>.</li>
<li>The variance of the errors is constant across all levels of the predictors; mathematically, we write <span class="math inline">\(Var\left(\varepsilon_i \mid (\text{Predictors 1 - }p)_i\right) = \sigma^2\)</span> for some unknown constant <span class="math inline">\(\sigma^2 &gt; 0\)</span>. This is sometimes referred to as homoskedasticity.</li>
<li>The error terms are independent; in particular, the magnitude of the error for one observation does not influence the magnitude of the error for any other observation.</li>
<li>The distribution of the errors follows a Normal distribution with the above mean and variance.</li>
</ol>
</div>
<p>It would be a mistake to consider the above conditions only from a probabilistic perspective; wrestling with what these mean in practice is critical to understanding the model.</p>
<p>The first condition says the structure of the model is correct; that is, no variables were omitted and the functional form of the response is really determined by a linear combination of the predictors. Violations of this assumption are very serious and indicate a different model structure is needed. Essentially, if we believe this condition is not met, it means we should revisit the science and rationale behind the proposed model because it is likely invalid.</p>
<p>The second condition considers the precision with which the response is measured. The condition asserts that this precision is consistent across all possible values for the predictors. For example, consider the academic performance of two classes; this condition prohibits cases in which the grades for one class have a wider range than the grades for the other.</p>
<p>The third condition eliminates data for which measurements are related beyond sharing common values of the predictors in the model. For example, suppose we are modeling the height of a tree as a function of its age. All trees of a similar age may be “related” in the sense that we expect them to have similar heights; the model allows this. However, it does not allow for trees being “related” in the sense that trees in a similar region will share a similar height due to differences in resources among regions; this is prohibited because “region” is not captured by the model. In the biological sciences, this condition is often called into question when we take repeated measurements on subjects or when observations are measured close together in time. This type of data will be addressed later in the text (<a href="04b-rm-terminology.html"><span>Chapter&nbsp;13</span></a>).</p>
<p>The last condition is a strong one; it states that we are able to fully characterize the distribution of the error terms. While the other conditions describe certain characteristics of the distribution, this says we know the exact form of the distribution. Historically, this condition was imposed to ensure the error terms were well behaved (and because the probability theory worked out nicely).</p>
<p>Statistics courses (especially the introductory course) focus on these four conditions on the error. However, the classical framework typically also imposes additional conditions on the predictors.</p>
<div id="def-classical-regression-cont" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.4 (Classical Regression (Conditions on Predictors)) </strong></span>The classical regression model (<a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>) places the following conditions on the predictors:</p>
<ol type="1">
<li>Each predictor is measured without error.</li>
<li>Each predictor has an additive linear effect on the response.</li>
</ol>
</div>
<p>The first condition states that there cannot be any noise present in the measurement of the <em>predictors</em>. For example, imagine modeling the length (or height) of infants as a function of their age. When the doctor asks for the age of the child, we are assuming that this age can be computed/measured without error. This seems reasonable when the predictor is age. However, consider using the temperature of the infant as a predictor in the model; if the thermometer is only accurate to within 2 tenths of a degree, than we may believe that the body temperature is measured with error. Addressing measurement error in models is beyond the scope of this text, and it is in general a difficult problem. Typically, even if a predictor is potentially measured with error, we are able to assume the error is negligible compared to the amount of error in the response. Throughout the text, we will assume all predictors are measured without error.</p>
<p>The second condition on the predictors is very closely related to the condition on the errors that the mean of the errors is 0. If we are empirically building a model and find evidence that the model has been mis-specified, it is generally a result of the predictors not having a linear relationship with the response.</p>
</section>
<section id="alternate-characterization-of-the-model" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="alternate-characterization-of-the-model"><span class="header-section-number">4.3</span> Alternate Characterization of the Model</h2>
<p>Recall that a distribution is just the pattern of variability among the values of a variable; that is, a distribution describes how values differ from one another. <a href="01d-essential-probability.html"><span>Chapter&nbsp;3</span></a> presented probability tools that can be used to model these distributions. We saw that it is possible to specify these models up to some unknown parameters; for example, we may write <span class="math inline">\(X \sim N\left(\mu, \sigma^2\right)\)</span> in order to say the density of the random variable <span class="math inline">\(X\)</span> can be modeled using the following mathematical formula:</p>
<p><span class="math display">\[\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2\sigma^2}\left(x - \mu\right)^2}.\]</span></p>
<p>We often think about these parameters as being a single value, but nothing prohibits that value from being described by a function of variables. That is, we could let <span class="math inline">\(\mu = g(\text{Predictors})\)</span> for some function <span class="math inline">\(g\)</span>. In fact, the conditions on the error term specified in the previous section lead us to an alternate characterization of the general linear model.</p>
<div id="def-alternate-characterization" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.5 (Alternate Characterization of the Classical Regression Model) </strong></span>Under the classical regression conditions on the error term (see <a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>), we can characterize the classical regression model as</p>
<p><span class="math display">\[(\text{Response})_i \mid (\text{Predictors 1 through } p)_i \stackrel{\text{Ind}}{\sim} N\left(\beta_0 + \sum\limits_{j=1}^{p} \beta_j (\text{Predictor } j)_i, \sigma^2\right).\]</span></p>
<p>Here, the symbol <span class="math inline">\(\mid\)</span> is read “given” and means that the distribution of the response is specified after knowing the values of the predictors. That is, the distribution of the response depends on these variables.</p>
</div>
<p>The alternate characterization of the regression model in <a href="#def-alternate-characterization">Definition&nbsp;<span>4.5</span></a> is particularly useful in statistical theory, but that is not why we mention it here. We mention this form because it sheds light on the true nature of regression models (beyond just the classical regression model) — regression models characterize the distribution of the response.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>Regression models allow the parameters characterizing the distribution of the population to depend on the predictors through some function.</p>
</div>
</div>
<p>Closely examining <a href="#def-alternate-characterization">Definition&nbsp;<span>4.5</span></a>, we see that the deterministic portion of the general linear model is actually characterizing the <em>mean</em> of the response (for specified values of the predictors). In fact, this realization is actually the direct result of the first (“mean 0”) condition we placed on the error terms. This is what allows us to begin interpreting the parameters in the model.</p>
</section>
<section id="interpretation-of-parameters" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="interpretation-of-parameters"><span class="header-section-number">4.4</span> Interpretation of Parameters</h2>
<p>When we assume that the error in the response, on average, is 0 for all values of the predictor, we are really saying that the deterministic portion of the model defines the mean response. We see this in the alternate characterization of the regression model above where <span class="math inline">\(\mu\)</span> in the Gaussian (Normal) model is replaced by</p>
<p><span class="math display">\[\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i.\]</span></p>
<p>Notice what happens if we plug zero in for <em>every</em> predictor:</p>
<p><span class="math display">\[\beta_0 + \sum_{j=1}^{p} \beta_j (0) = \beta_0.\]</span></p>
<p>Since this deterministic portion specifies the average response, then we see that the average response is <span class="math inline">\(\beta_0\)</span> when all predictors have the value zero.</p>
<div id="def-intercept" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.6 (Intercept) </strong></span>The population intercept, denoted <span class="math inline">\(\beta_0\)</span>, is the <em>mean</em> response when all predictors take the value zero.</p>
</div>
<p>We should point out that while this is the correct interpretation, it may not always make sense in context. For example, if we are modeling the heart rate of patients as a function of their body temperature and weight; the model would have the form</p>
<p><span class="math display">\[(\text{Heart Rate})_i = \beta_0 + \beta_1 (\text{Body Temperature})_i + \beta_2 (\text{Weight})_i + \varepsilon_i.\]</span></p>
<p>Based on <a href="#def-intercept">Definition&nbsp;<span>4.6</span></a>, we would interpret the intercept in this model as the average heart rate for individuals with a body temperature of zero degrees and a weight of zero pounds; as this group of individuals does not exist, the interpretation does not make sense in this context.</p>
<p>We now turn to considering an interpretation for the slope. Consider two groups of individuals:</p>
<ul>
<li>Group 1 has the value <span class="math inline">\(a\)</span> for the first predictor and value <span class="math inline">\(x_j\)</span> for Predictor <span class="math inline">\(j\)</span> (for <span class="math inline">\(j = 2, \dotsc, p\)</span>).</li>
<li>Group 2 has the value <span class="math inline">\(a + 1\)</span> for the first predictor and value <span class="math inline">\(x_j\)</span> for Predictor <span class="math inline">\(j\)</span> for <span class="math inline">\(j = 2, \dotsc, p\)</span>.</li>
</ul>
<p>That is, the only way the two groups differ is that Group 2 has increased the value of the first predictor by 1. From our model, we have that the average response for Group 1 is</p>
<p><span class="math display">\[\beta_0 + \beta_1 a + \sum_{j=2}^{p} \beta_j x_j.\]</span></p>
<p>The average response for Group 2 is</p>
<p><span class="math display">\[\beta_0 + \beta_1 (a + 1) \sum_{j=2}^{p} \beta_j x_j.\]</span></p>
<p>Consider taking the difference in these two <em>mean</em> responses (Group 2 minus Group 1):</p>
<p><span class="math display">\[\beta_0 + \beta_1 (a + 1) \sum_{j=2}^{p} \beta_j x_j - \left(\beta_0 + \beta_1 a + \sum_{j=2}^{p} \beta_j x_j\right) = \beta_1.\]</span></p>
<p>That is, the slope is the difference in the <em>mean</em> response between the two groups.</p>
<div id="def-slope" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.7 (Slope) </strong></span>The coefficient for the <span class="math inline">\(j\)</span>-th predictor, denoted <span class="math inline">\(\beta_j\)</span>, is the change in the mean response associated with a one unit increase in Predictor <span class="math inline">\(j\)</span>, <em>holding all other predictors fixed</em>.</p>
</div>
<p>The last part of <a href="#def-slope">Definition&nbsp;<span>4.7</span></a> is a critical part of the interpretation, and it is critical to the full utility of regression models. Again, while holding all other predictors fixed may not be practically feasible (for example, could we really increase an individual’s height without also increasing their weight), it allows us to investigate the impact of a predictor separate from other variables.</p>
<p>Interpretation of the parameters is a large step beyond simply estimating the parameters. However, we still have not developed the tools to do much beyond estimation. We now turn our attention to inference.</p>
</section>
<section id="inference-about-the-mean-parameters" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="inference-about-the-mean-parameters"><span class="header-section-number">4.5</span> Inference About the Mean Parameters</h2>
<p>As suggested in <a href="01c-distributional-quartet.html"><span>Chapter&nbsp;2</span></a>, the key to making formal inference on the parameters of a population is to develop a model for the sampling distribution (or null distribution) of the corresponding statistics. Under the classical regression conditions of <a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>, we are able to form an exact model for the sampling distribution of the least squares estimates.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>While beyond the scope of this course, it can be shown that the least squares estimates of the parameters are linear combinations of the observed responses. This, combined with the modeling assumptions, allows us to construct a model for the sampling distribution of the estimates.</p>
</div>
</div>
<div id="def-ls-sampling-distribution" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.8 (Sampling Distribution of the Least Squares Estimates) </strong></span>Under the classical regression conditions (<a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>), we have that</p>
<p><span class="math display">\[\frac{\widehat{\beta}_j - \beta_j}{\sqrt{Var\left(\widehat{\beta}_j\right)}} \sim t_{n - p - 1}.\]</span></p>
<p>The denominator <span class="math inline">\(\sqrt{Var\left(\widehat{\beta}_j\right)}\)</span> is known as the <em>standard error</em> of the estimate <span class="math inline">\(\widehat{\beta}_j\)</span>. This formula holds for all <span class="math inline">\(j = 0, 1, \dotsc, p\)</span>.</p>
</div>
<p><a href="#def-ls-sampling-distribution">Definition&nbsp;<span>4.8</span></a> states the standardized difference between our estimate and the parameter follows a t-distribution, where the degrees of freedom depend on the sample size and the number of parameters in the model. The specific model is not as important as knowing that under the classical regression conditions, an exact model is known. Nearly every software package that implements regression does so under the classical regression conditions, and the inference is based on the above model for the sampling distribution.</p>
<p>The detail-oriented reader will note that we did not include a formula for the standard error of an estimate. The formula is beyond the scope of this course, but it is a function of the values of the predictor as well as the variability in the error term. You see, the moment we specified the second condition (“constant variance”), we introduced another parameter: <span class="math inline">\(\sigma^2\)</span>. The parameter <span class="math inline">\(\sigma^2\)</span> does not govern the mean response; so, it tends to be of less direct interest for our purposes. Instead, it characterizes the variability in the response (for a given set of predictors), and it plays a role in inference (as we see in the above model for the sampling distribution of the least squares estimates of the parameters in the mean model). It will therefore play a role in computing confidence intervals and p-values. Since it is unknown, it must also be estimated.</p>
<div id="def-estimate-sigma2" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.9 (Estimate of the Variance of the Errors) </strong></span>The unknown variance in the linear model, which captures the variability in the response for any set of predictors (also called the residual variance), is estimated by</p>
<p><span class="math display">\[\widehat{\sigma}^2 = \frac{1}{n-p-1} \sum\limits_{i=1}^{n} \left((\text{Response})_i - \widehat{\beta}_0 - \sum\limits_{j=1}^{p} \widehat{\beta}_j (\text{Predictor } j)_{i}\right)^2.\]</span></p>
</div>
<p>Note that the estimate of the variance depends upon the least squares estimates. Of more interest is that the scaling factor <span class="math inline">\((n - p - 1)\)</span> is the same as the degrees of freedom for the sampling distribution; that is not an accident.</p>
<p>A model for the sampling distribution is the holy grail of statistical inference. It can be updated to determine the model for the null distribution. And, once you have a model for the sampling distribution in hand, you can wield it to construct a confidence interval (and null distributions to yield p-values).</p>
<div id="def-classical-ci" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.10 (Confidence Interval for Parameters Under Classical Model) </strong></span>Under the classical regression conditions (<a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>), a <span class="math inline">\(100c\)</span>% confidence interval for the parameter <span class="math inline">\(\beta_j\)</span> is given by</p>
<p><span class="math display">\[\widehat{\beta}_j \pm t_{n-p-1, 0.5(1+c)} \sqrt{Var\left(\widehat{\beta}_j\right)}.\]</span></p>
<p>where <span class="math inline">\(t_{n-p-1, 0.5(1+c)}\)</span> is the <span class="math inline">\(0.5(1+c)\)</span> quantile from the <span class="math inline">\(t_{n-p-1}\)</span> distribution, known as the critical value for the confidence interval.</p>
</div>
<p>Like many confidence intervals, the idea is that we are grabbing the middle portion of the model for the sampling distribution. The confidence interval represents the values of the parameter for which the data is consistent — the reasonable values of the parameter based on the observed data. Also note that this confidence interval is specified for each parameter individually.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For large values of <span class="math inline">\(n\)</span> relative to <span class="math inline">\(p\)</span>, the critical value for a 95% confidence interval is approximately 1.96. Hence, a rough confidence interval is therefore 2 standard errors in either direction of the point estimate.</p>
</div>
</div>
<div id="def-classical-p" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.11 (P-Value for Testing if Parameter Belongs in Model Under Classical Model) </strong></span>Under the classical regression conditions (<a href="#def-classical-regression">Definition&nbsp;<span>4.3</span></a>), the p-value for testing the hypotheses</p>
<p><span class="math display">\[H_0: \beta_j = 0 \qquad \text{vs.} \qquad H_1: \beta_j \neq 0\]</span></p>
<p>is given by</p>
<p><span class="math display">\[Pr\left(\lvert T\rvert &gt; \lvert\frac{\widehat{\beta}_j}{\sqrt{Var\left(\widehat{\beta}_j\right)}}\rvert\right)\]</span></p>
<p>where <span class="math inline">\(T \sim t_{n-p-1}\)</span>.</p>
</div>
<p><a href="#def-classical-p">Definition&nbsp;<span>4.11</span></a> highlights that the null distribution for the standardized ratio is developed by taking the model for the sampling distribution and enforcing the null hypothesis <span class="math inline">\(\left(\beta_j = 0\right)\)</span>. Using this null distribution, our p-value then summarizes how likely it is we would obtain a value of the standardized statistic at least as large of that observed by chance alone when the null hypothesis is true.</p>
<p>The interpretation of the confidence interval and p-value follows the interpretation of the confidence intervals and p-values computed in an introductory course (and reviewed in <a href="01b-statistical-process.html"><span>Chapter&nbsp;1</span></a>. This section just establishes that the conditions we placed on the error term yield explicit formulas for their computation (even if these formulas are implemented in the background of the software).</p>
<p>The framework introduced here provides the basics for making inference using a statistical model. As we consider more flexible modeling strategies, these key concepts do not leave us. We need a model for the sampling distribution or null distribution in order to make inference. And, the model for that distribution depends on the conditions we are willing to make.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>A model for the sampling distribution (and/or null distribution) is needed for making inference, and that model depends on the conditions we are willing to impose on the model for the data generating process.</p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02a-glm.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Unit II: General Linear Model</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02c-glm-assessing-conditions.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Assessing the Conditions for the General Linear Model</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>