<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Modeling for the Biological Sciences - 18&nbsp; Logistic Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05e-nlm-selection.html" rel="next">
<link href="./05c-nlm-heteroskedasticity.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="mystyles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05a-nlm.html">Unit V: Nonlinear Models</a></li><li class="breadcrumb-item"><a href="./05d-nlm-logistic.html"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Biostatistics</a> 
        <div class="sidebar-tools-main">
    <a href="./ma482-text.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01a-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit I: Review of Statistics and Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01b-statistical-process.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Overview of the Statistical Process</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01c-distributional-quartet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Distributional Quartet</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01d-essential-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Essential Probability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02a-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit II: General Linear Model</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02b-glm-model-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">General Linear Model Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02c-glm-assessing-conditions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Assessing the Conditions for the General Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02d-glm-unifying-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The General Linear Model as a Unifying Framework</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03a-modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit III: General Modeling Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03b-modeling-related-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addressing Relationships Between Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03c-modeling-categorical-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Incorporating Categorical Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03d-modeling-interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Allowing Effect Modification (Interaction Terms)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03e-modeling-linear-hypotheses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">General Linear Hypothesis Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03f-modeling-large-sample-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Large Sample Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03g-modeling-splines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Modeling Curvature (Splines)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04a-rm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit IV: Models for Repeated Measures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04b-rm-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">The Language of Repeated Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04c-rm-mixed-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixed Effects Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04d-rm-gee.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Generalized Estimating Equations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05a-nlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit V: Nonlinear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05b-nlm-model-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Nonlinear Model Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05c-nlm-heteroskedasticity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Relaxing the Constant Variance Condition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05d-nlm-logistic.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05e-nlm-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05f-nlm-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Estimation Details for Nonlinear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05g-nlm-rm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Nonlinear Models with Repeated Measures</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./06a-surv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit VI: Survival Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06b-surv-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">The Language of Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06c-surv-censoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Censoring</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06d-surv-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Basic Estimation and Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06e-surv-cph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Proportional Hazards Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#considerations-for-a-binary-response" id="toc-considerations-for-a-binary-response" class="nav-link active" data-scroll-target="#considerations-for-a-binary-response"><span class="header-section-number">18.1</span> Considerations for a Binary Response</a></li>
  <li><a href="#the-logistic-regression-model" id="toc-the-logistic-regression-model" class="nav-link" data-scroll-target="#the-logistic-regression-model"><span class="header-section-number">18.2</span> The Logistic Regression Model</a></li>
  <li><a href="#estimation-of-the-parameters" id="toc-estimation-of-the-parameters" class="nav-link" data-scroll-target="#estimation-of-the-parameters"><span class="header-section-number">18.3</span> Estimation of the Parameters</a></li>
  <li><a href="#inference-on-the-parameters" id="toc-inference-on-the-parameters" class="nav-link" data-scroll-target="#inference-on-the-parameters"><span class="header-section-number">18.4</span> Inference on the Parameters</a></li>
  <li><a href="#interpretation-of-parameters" id="toc-interpretation-of-parameters" class="nav-link" data-scroll-target="#interpretation-of-parameters"><span class="header-section-number">18.5</span> Interpretation of Parameters</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-nlm-logistic" class="quarto-section-identifier"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>When the response is binary (taking one of only two values), the models we have discussed so far in this text are inappropriate. To see some of the complications, consider trying to characterize the impact of lifestyle choices on whether an individual is diagnosed with cancer. The response (is a person diagnosed with cancer, yes/no) does not readily fit into a framework such as</p>
<p><span class="math display">\[(\text{Response})_i = f\left((\text{Predictors})_i, \boldsymbol{\beta}\right) + \varepsilon_i.\]</span></p>
<p>To begin with, the left-hand side is not a number, but a categorical variable. We could potentially address this using an indicator variable:</p>
<p><span class="math display">\[(\text{Cancer Diagnosis})_i = \begin{cases} 1 &amp; \text{if i-th subject diagnosed with cancer} \\ 0 &amp; \text{otherwise} \end{cases};\]</span></p>
<p>we could use this indicator variable as the response. However, we now have another issue; the right-hand side of the model would need to only return either a 0 or a 1. The response will <em>never</em> be 0.96; as a result, the idea of <span class="math inline">\(\varepsilon_i\)</span> being errors that “jitter” the observed response from some overall mean response is no longer reasonable.</p>
<p>Recall that in developing our approach to nonlinear models, we specifically did not consider the “signal plus noise” approach and instead chose to specify a semiparametric model (<a href="05b-nlm-model-framework.html#def-semiparametric-nonlinear-model">Definition&nbsp;<span>16.2</span></a>). This approach is general enough to permit binary responses. Specifically, when the response is binary, the most common technique is logistic regression, which is the focus of this chapter.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Many other texts consider logistic regression to be a separate topic from nonlinear models; however, the structure of the logistic regression model is nonlinear in the parameters. We present it in this unit as a way of linking to ideas we have already discussed.</p>
</div>
</div>
<section id="considerations-for-a-binary-response" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="considerations-for-a-binary-response"><span class="header-section-number">18.1</span> Considerations for a Binary Response</h2>
<p>The benefit of the nonlinear model framework we outlined in <a href="05b-nlm-model-framework.html"><span>Chapter&nbsp;16</span></a> is that it emphasizes that regression models simply characterize the aspects of the distribution of the response we are confident about. When the response is binary, we actually know quite a bit about the distribution of the response.</p>
<p><a href="01d-essential-probability.html"><span>Chapter&nbsp;3</span></a> introduced common models for the distribution of a random variable. When the random variable is quantitative, there are many potential distributional models. However, when the response is binary, there is only a single model for characterizing the distribution: the Bernoulli distribution (<a href="01d-essential-probability.html#def-bernoulli-distribution">Definition&nbsp;<span>3.6</span></a>). Therefore, we can leverage that in developing a model for a binary response.</p>
<p>In particular, the Bernoulli distribution states that the mean response <span class="math inline">\(p\)</span> represents the probability the response takes the value 1 (representing a “success”); and, <span class="math inline">\(p\)</span> is constrained to be between 0 and 1. Further, the variance of the response is determined by the mean response: <span class="math inline">\(p (1 - p)\)</span>. Of course, the definition of the Bernoulli distribution considers the parameter <span class="math inline">\(p\)</span> to be a single value. As we have seen, regression models allow the distribution to depend on additional predictors.</p>
<p>Placing this in the nonlinear model framework, we might say</p>
<p><span class="math display">\[
\begin{aligned}
  E\left[(\text{Response})_i \mid (\text{Predictors})_i\right]
    &amp;= f\left((\text{Predictors})_i, \boldsymbol{\beta}\right) \\
  Var\left[(\text{Response})_i \mid (\text{Predictors})_i\right]
    &amp;= f\left((\text{Predictors})_i, \boldsymbol{\beta}\right) \left(1 - f\left((\text{Predictors})_i, \boldsymbol{\beta}\right)\right).
\end{aligned}
\]</span></p>
<p>The mean response function <span class="math inline">\(f(\cdot)\)</span> is allowing the mean response (<span class="math inline">\(p\)</span> in the Bernoulli distribution) to depend upon the predictors. And, once the mean response function is specified, the variance is known (through the relationship <span class="math inline">\(p (1 - p)\)</span>). However, since we know that the response is binary, we can go further and say not only is this an appropriate mean and variance function, but we know the distribution as well; that is,</p>
<p><span class="math display">\[(\text{Response})_i \mid (\text{Predictors})_i \stackrel{\text{Ind}}{\sim} Ber\left[f\left((\text{Predictors})_i, \boldsymbol{\beta}\right)\right],\]</span></p>
<p>where we are assuming that each response is independent of all others. Remember, nothing about the nonlinear modeling framework prohibited making distributional assumptions; we just often were unwilling to. Here, we know the distribution; so, we include it as part of the model.</p>
<p>Of course, the nature of the binary response impacts our choice of the mean response function <span class="math inline">\(f(\cdot)\)</span>. In particular, the Bernoulli distributional model tells us that the mean response represents the probability the response takes the value 1. In our working example, this would be the probability of a subject receiving a cancer diagnosis given the value of the predictors. And, we know that probabilities must be between 0 and 1. Therefore, we must choose a mean response function <span class="math inline">\(f(\cdot)\)</span> which has a range on the interval 0 to 1.</p>
<p>This last point is what prohibits using linear regression with a binary response. The mean response function should represent a probability, but it is entirely likely that linear regression will result in probabilities less than 0 or larger than 1. Therefore, any reasonable choice of <span class="math inline">\(f(\cdot)\)</span> will be nonlinear in the parameters.</p>
<p>While technically any function <span class="math inline">\(f(\cdot)\)</span> that has a range on 0 to 1 is possible, one choice has dominated the literature in applied sciences for many years.</p>
</section>
<section id="the-logistic-regression-model" class="level2" data-number="18.2">
<h2 data-number="18.2" class="anchored" data-anchor-id="the-logistic-regression-model"><span class="header-section-number">18.2</span> The Logistic Regression Model</h2>
<p>If we want a large class of functions <span class="math inline">\(f(\cdot)\)</span> that have a range on 0 to 1, we need only look to any cumulative distribution function (<a href="01d-essential-probability.html#def-cdf">Definition&nbsp;<span>3.3</span></a>). The most popular choice in practice is the cumulative distribution function of the Logistic distribution:</p>
<p><span class="math display">\[f(x) = \frac{e^x}{1 + e^x}.\]</span></p>
<p>This leads to the logistic regression model.</p>
<div id="def-logistic-regression" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.1 (Logistic Regression Model) </strong></span>A model for binary responses where the response, given the predictors, has a Bernoulli distribution such that</p>
<p><span id="eq-nlm-logistic-model"><span class="math display">\[Pr\left((\text{Response})_i = 1 \mid (\text{Predictors})_i\right) =
    \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}} \tag{18.1}\]</span></span></p>
<p>and all responses are independent of one another.</p>
</div>
<p>Notice that we took the term in the exponents of <a href="app-glossary.html#eq-nlm-logistic-model">Equation&nbsp;<span>A.1</span></a> to be</p>
<p><span class="math display">\[\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i,\]</span></p>
<p>a linear combination of the parameters. While not a requirement, this is common in practice since any additional curvature could be captured through flexible modeling techniques like splines. As a result, this term in the exponent is often referred to as the “linear predictor.”</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Do not be fooled by the linear combination of the parameters in the linear predictor. The logistic regression model is nonlinear in the parameters since the linear predictor appears in an exponent.</p>
</div>
</div>
<p>As stated above, by specifying the mean response function in <a href="app-glossary.html#eq-nlm-logistic-model">Equation&nbsp;<span>A.1</span></a>, we have also specified the variance of the response. It will have the form</p>
<p><span class="math display">\[\left(\frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}\right)\left(1 - \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}\right).\]</span></p>
<p>We point this out to emphasize that the variance is not constant! Instead of addressing the non-constant variance through the wild bootstrap, we are modeling the structure of the variance directly.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>While not presented this way, it is possible to envision a binary response as the result of a latent (unobserved) quantitative response. For example, whether a student “graduates with honors” is a binary response (they either do or do not); but, it is the result of discretizing a quantitative measure (the student’s GPA). Thinking of the observed binary response as a discretation of some <em>unobserved</em> quantitative measure, with proper assumptions on the error term, results in the logistic regression model.</p>
</div>
</div>
</section>
<section id="estimation-of-the-parameters" class="level2" data-number="18.3">
<h2 data-number="18.3" class="anchored" data-anchor-id="estimation-of-the-parameters"><span class="header-section-number">18.3</span> Estimation of the Parameters</h2>
<p>The logistic regression model not only specifies the form of the mean and variance of the response; it also specifies the distributional model. As a result, we could specify the density function of the response given the predictors. Proceeding by estimating the parameters using least squares (as advocated in <a href="05b-nlm-model-framework.html"><span>Chapter&nbsp;16</span></a>) would actually ignore this additional information. When a parametric model is specified, we should take advantage of the additional structure (knowing the form of the density function) when estimating the parameters. This is accomplished through likelihood theory.</p>
<p>While a full development of likelihood theory is beyond the scope of this text, we motivate its use. In a probability course, the density function of a random variable is fully known, and we use it to compute the probability of the random variable taking on specific values. In a statistics course, we work in reverse. We have already observed specific outcomes; but, the density function is not fully known (as the parameters are unknown). We want to choose values of the unknown parameters that would result in a density function making the observed data as likely as possible.</p>
<p>Consider a specific example. Suppose we <em>spin</em> a penny 100 times and observe it landing “tails-side up” in 82 of those trials. If you had to guess at the true probability of a penny landing “tails-side up” when spun, what would you guess based on this data? Putting it into our logistic model framework, consider the indicator</p>
<p><span class="math display">\[
(\text{Tails})_i = \begin{cases} 1 &amp; \text{if i-th spin lands tails-side up} \\ 0 &amp; \text{otherwise;} \end{cases}
\]</span></p>
<p>then, our logistic model (with no predictors) has the form</p>
<p><span class="math display">\[Pr\left((\text{Tails})_i = 1\right) = \frac{e^{\beta_0}}{1 + e^{\beta_0}}.\]</span></p>
<p>We want to choose a value of <span class="math inline">\(\beta_0\)</span> which makes it as likely as possible (maximizes the probability) that in a new sample of 100 spun pennies, 82 would land tails-side up (matching what we observed in the sample). That is, we want to choose the value of the parameter that maximizes the probability of seeing our observed data. Since the observed data is the only information we have about the process, we want a model that aligns with this data as closely as possible; or more accurately, we want the data to align with the model as closely as possible. Hopefully, it is intuitive that if <em>in reality</em> (where “reality” depends on the value of the unknown parameter <span class="math inline">\(\beta_0\)</span>), a penny lands “tails-side up” 82% of the time, that makes this observed data much more likely than if <em>in reality</em>, it lands “tails-side up” only 50% of the time. Therefore, we would want the above probability to be equal to 0.82, leading to an estimate of <span class="math inline">\(\beta_0\)</span> of 1.516.</p>
<p>To help with visualizing this process, <a href="#fig-nlm-coins-likelihood">Figure&nbsp;<span>18.1</span></a> reports the probability of observing 82 coins (out of a sample of 100) land “tails-side up” as the value of <span class="math inline">\(\beta_0\)</span> changes. The likelihood is maximized when we set the true value of a “tails-side up” at being 0.82 (corresponding to <span class="math inline">\(\beta_0 = 1.516\)</span>). Other values can make the data likely, but not as likely as that value.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-nlm-coins-likelihood" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/fig-nlm-coins-likelihood-1.png" class="img-fluid figure-img" style="width:80.0%" alt="Line plot with the peak at 1.516."></p>
<figcaption class="figure-caption">Figure&nbsp;18.1: Likelihood of observing 82 coins land tails-side up when spinning 100 independent pennies. The likelihood is computed for various values of the parameter governing an intercept-only logistic regression model.</figcaption>
</figure>
</div>
</div>
</div>
<p>We generalize this to saying that for a fully parametric nonlinear model (such as logistic regression), it is best to choose the values of the parameters that maximize the likelihood function.</p>
<div id="def-likelihood-function" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.2 (Likelihood Function) </strong></span>For a fully parametric model, the likelihood function <span class="math inline">\(\mathcal{L}(\boldsymbol{\beta}, \text{Observed Data})\)</span> captures how likely the observed data is to be realized in a future study under a specific set of parameters. This is directly related to the density function of the parametric model assumed.</p>
</div>
<div id="def-mle" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.3 (Maximum Likelihood Estimation) </strong></span>The method of maximum likelihood estimation chooses parameter estimates to maximize the likelihood function under an assumed parametric model. The resulting estimates are known as maximum likelihood estimates.</p>
</div>
<p>While the actual form is not critical to our exposition, for completeness, the likelihood function corresponding to logistic regression is</p>
<p><span class="math display">\[\prod_{i=1}^{n} \left(\frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}\right)^{(\text{Response})_i}\left(1 - \frac{e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}{1 + e^{\beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i}}\right)^{1 - (\text{Response})_i}\]</span></p>
<p>where <span class="math inline">\((\text{Response})_i\)</span> is an indicator value taking the value 1 or 0. Maximizing this likelihood is done numerically. While the details of this process are beyond the scope of this text, the procedure is similar to the least-squares procedure discussed in <a href="05f-nlm-estimation.html"><span>Chapter&nbsp;20</span></a>.</p>
</section>
<section id="inference-on-the-parameters" class="level2" data-number="18.4">
<h2 data-number="18.4" class="anchored" data-anchor-id="inference-on-the-parameters"><span class="header-section-number">18.4</span> Inference on the Parameters</h2>
<p>In order to make inference about the parameters, we need a model for the sampling distribution of the parameter estimates. Likelihood theory provides results for modeling the sampling distribution of maximum likelihood estimates. Generally, these results rely on large sample theory (though empirical models could be developed).</p>
<div id="def-nlm-logistic-samp-distns" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.4 (Large Sample Sampling Distribution of Parameter Estimates in Logistic Regression) </strong></span>Consider the logistic regression model in <a href="#def-logistic-regression">Definition&nbsp;<span>18.1</span></a>. Assuming the form of the model is correctly specified with parameter vector <span class="math inline">\(\boldsymbol{\beta}\)</span>, as the sample size gets large, we have that</p>
<p><span class="math display">\[\frac{\widehat{\beta}_j - \beta_j}{\sqrt{Var\left(\widehat{\beta}_j\right)}} \sim N(0, 1)\]</span></p>
<p>for all <span class="math inline">\(j = 1, \dotsc, p\)</span>. Further, under the null hypothesis</p>
<p><span class="math display">\[H_0: \mathbf{K}\boldsymbol{\beta} = \mathbf{m}\]</span></p>
<p>we have</p>
<p><span class="math display">\[\left(\mathbf{K}\widehat{\boldsymbol{\beta}} - \mathbf{m}\right)^\top \left(\mathbf{K}\widehat{\boldsymbol{\Sigma}}\mathbf{K}^\top\right)^{-1} \left(\mathbf{K}\widehat{\boldsymbol{\beta}} - \mathbf{m}\right) \sim \chi^2_r\]</span></p>
<p>where <span class="math inline">\(r\)</span> is the rank (number of rows) of <span class="math inline">\(\mathbf{K}\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Though the above results require large sample sizes, generally fitting a logistic regression model itself requires a relatively large sample size (the less variability in the response, the harder it is to fit a model). As a result, being able to estimate the parameters often means the sample size is large enough to rely on the default inference.</p>
</div>
</div>
<p>As stated in <a href="05b-nlm-model-framework.html"><span>Chapter&nbsp;16</span></a>, adding distributional assumptions does not avoid the need for large sample inference. The difference is primarily in the estimation process (least squares compared to maximum likelihood). When we do know the distributional model (as in the case of logistic regression), it turns out maximum likelihood estimation is optimal.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>When we have a binary response, we <em>know</em> it has a Bernoulli distribution. As a result, we do not need to posit a model for the distribution. However, that does not guarantee our model is specified correctly in logistic regression because we may have misspecified the mean response function.</p>
</div>
</div>
<p>The above results allow us to not only construct confidence intervals, but we can also make use of the general linear hypothesis testing framework for testing specific hypotheses. That is, our inference is not all that different than under the linear model framework once we have estimates for the parameters and estimates for their standard errors.</p>
</section>
<section id="interpretation-of-parameters" class="level2" data-number="18.5">
<h2 data-number="18.5" class="anchored" data-anchor-id="interpretation-of-parameters"><span class="header-section-number">18.5</span> Interpretation of Parameters</h2>
<p>The parameters in a logistic regression model have a nice interpretation; however, that interpretation is not a natural interpretation for most individuals. In order to understand what is happening, we need to think in terms of odds of an event instead of probability of an event.</p>
<div id="def-odds" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.5 (Odds) </strong></span>The odds of an event with probability <span class="math inline">\(p\)</span> is defined as</p>
<p><span class="math display">\[\frac{p}{1-p}.\]</span></p>
</div>
<p>We often hear odds presented in terms of integers. Such as, “there are 3-to-1 odds the event will occur.” This would mean that out of four trials, we would expect the event to happen 3 times; this corresponds to <span class="math inline">\(p = 0.75\)</span> and therefore <span class="math inline">\(1 - p = 0.25\)</span> giving an odds of 3. While many of us think in terms of probabilities, clinicians tend to think in terms of the odds of an event. As a result, it is natural to clinicians to compare the odds of an event under two scenarios instead of comparing the probability of an event under two scenarios.</p>
<div id="def-or" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.6 (Odds Ratio) </strong></span>The odds ratio is a method of comparing two events; typically, it is formed by the ratio of the odds of the same event under two different scenarios. Let <span class="math inline">\(p_1\)</span> be the probability of the event under scenario 1 and let <span class="math inline">\(p_2\)</span> be the probability of an event under scenario 2; then, the odds of the event under scenario 1 are</p>
<p><span class="math display">\[\gamma_1 = \frac{p_1}{1 - p_1},\]</span></p>
<p>and the odds of the event under scenario 2 are</p>
<p><span class="math display">\[\gamma_2 = \frac{p_2}{1 - p_2}.\]</span></p>
<p>The odds ratio comparing scenario 1 to scenario 2 is</p>
<p><span class="math display">\[OR = \frac{\gamma_1}{\gamma_2} = \left(\frac{p_1}{1 - p_1}\right) \left(\frac{1 - p_2}{p_2}\right).\]</span></p>
</div>
<p>If the odds of the event are the same under both scenarios, we obtain an odds ratio of 1. Odds ratios larger than 1 indicate that the event is more likely to occur (has greater odds) under scenario 1. Odds ratios less than 1 indicate that the event is less likely to occur (has lower odds) under scenario 1.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The odds ratio should not be confused with the relative risk. The relative risk of an event is the ratio of the probabilities under two scenarios. That is, under the setup of <a href="#def-or">Definition&nbsp;<span>18.6</span></a>, the relative risk comparing scenario 1 to scenario 2 is</p>
<p><span class="math display">\[\frac{p_1}{p_2}.\]</span></p>
<p>A relative risk of 4 says that the <em>probability</em> of the event is 4 times as large under scenario 1. An odds ratio of 4 says that the <em>odds</em> of an event are 4 times as large under scenario 1.</p>
</div>
</div>
<p>Now, let’s return to our logistic regression model. Consider a model with two predictors:</p>
<p><span class="math display">\[Pr\left((\text{Response})_i = 1 \mid (\text{Predictors})_i \right) = \frac{\exp\left\{\beta_0 + \beta_1 (\text{Predictor 1})_i + \beta_2 (\text{Predictor 2})_i\right\}}{1 + \exp\left\{\beta_0 + \beta_1 (\text{Predictor 1})_i + \beta_2 (\text{Predictor 2})_i\right\}}.\]</span></p>
<p>Consider the group of subjects where Predictor 1 takes the value <span class="math inline">\(a\)</span> and Predictor 2 takes the value <span class="math inline">\(b\)</span>. Then, the probability the response takes the value 1 in this group is</p>
<p><span class="math display">\[p_a = \frac{e^{\beta_0 + \beta_1 a + \beta_2 b}}{1 + e^{\beta_0 + \beta_1 a + \beta_2 b}},\]</span></p>
<p>and the odds of the response taking the value 1 are</p>
<p><span class="math display">\[\frac{p_a}{1 - p_a} = e^{\beta_0 + \beta_1 a + \beta_2 b}.\]</span></p>
<p>Now, consider the group of subjects where Predictor 1 takes the value <span class="math inline">\(a + 1\)</span> and Predictor 2 takes the value <span class="math inline">\(b\)</span>. Then, following the above process, we have that the probability the response takes the value 1 in this group is</p>
<p><span class="math display">\[p_{a+1} = \frac{e^{\beta_0 + \beta_1 (a + 1) + \beta_2 b}}{1 + e^{\beta_0 + \beta_1 (a + 1)+ \beta_2 b}},\]</span></p>
<p>and the odds of the response taking the value 1 are</p>
<p><span class="math display">\[\frac{p_{a+1}}{1 - p_{a+1}} = e^{\beta_0 + \beta_1 (a + 1) + \beta_2 b}.\]</span></p>
<p>Therefore, the odds ratio for the group with an increase in Predictor 1 relative to the other group is</p>
<p><span class="math display">\[\left(\frac{p_{a+1}}{1 - p_{a+1}}\right) \left(\frac{1 - p_a}{p_a}\right) = e^{\beta_1}.\]</span></p>
<p>That is, the parameters in the logistic regression model are directly related to the odds ratio.</p>
<div id="def-logistic-interpretation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 18.7 (Interpretation of Parameters in a Logistic Regression Model) </strong></span>Let <span class="math inline">\(\beta_j\)</span> be the parameter associated with the <span class="math inline">\(j\)</span>-th predictor in a logistic regression model (<a href="#def-logistic-regression">Definition&nbsp;<span>18.1</span></a>). Then, <span class="math inline">\(\beta_j\)</span> represents the log-OR (“log odds ratio”) associated with a one-unit increase in the <span class="math inline">\(j\)</span>-th predictor holding all other predictors fixed.</p>
</div>
<p>That is, exponentiating the <span class="math inline">\(j\)</span>-th coefficient gives the odds ratio comparing the odds of the event under two scenarios: when the <span class="math inline">\(j\)</span>-th predictor is increased by 1 unit relative to leaving it alone. Notice that unlike the linear model, increasing the <span class="math inline">\(j\)</span>-th predictor by 1 unit does not result in an additive effect on the mean response (the probability of the response occurring in this case). Instead, it has an additive effect on the log odds.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>When we use the word “log” throughout the text, we are always referring to the natural logarithm.</p>
</div>
</div>
<p>If a parameter in our model is 0, it will result in an odds ratio of 1, indicating no association between the response and predictor. A parameter larger than 0 results in an odds ratio larger than 1, indicating that the likelihood of the response increases as the predictor increases. A parameter smaller than 0 results in an odds ratio less than 1, indicating the likelihood of the response decreases as the predictor increases.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05c-nlm-heteroskedasticity.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Relaxing the Constant Variance Condition</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05e-nlm-selection.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Model Selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>