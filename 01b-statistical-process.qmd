# Overview of the Statistical Process {#sec-statistical-process}

{{< include _setupcode.qmd >}}

Research is about telling a story, and good data presentation and statistical inference can help tell that story in a compelling way.  This chapter cannot replace an introductory course on statistical analysis.  We strive to give practical advice for data storage, presentation, and analysis while presenting a framework for inference; it is within this context that we review terminology fundamental to our study of statistical models in the biological sciences.


## Overview of Drawing Inference
Every research question posed is trying to characterize a __population__.

:::{#def-population}
## Population
The collection of subjects we would like to say something about.
:::

It is often impossible (or impractical) to observe the entire population.  Instead, we make observations on a subset of the population; this smaller group is known as the __sample__.

:::{#def-sample}
## Sample
The collection of subjects for which we actually obtain measurements (data).
:::

:::{.callout-note}
We acknowledge the weight of the term "subject" when discussing human participants.  Medical research has not been immune to unjust practices exploiting marginalized groups within society.  While the term persists in the description of research practices in general, we opt for the term "participants" when describing those individuals who actually participate in a study.

While the semantics may seem a small component, this small shift adds a human element to the analysis.  It is important to remember that each observation within the data has a story, and when those stories represent the lives of others, they deserve our full respect.
:::

For each subject within the sample, we obtain a collection of measurements, which form our data.  This could be the result, for example, of a survey, examination of medical records, or a prospective study which follows subjects for a lengthy period of time.   The goal of statistical modeling is to use the sample (the group we actually observe) to say something about the population of interest (the group we wish we had observed); this process is known as __statistical inference__ and is illustrated in @fig-statistical-process-statistical-process.

:::{#def-inference}
## Statistical Inference
The process of using a sample to characterize some aspect of the underlying population.
:::

```{r}
#| label: fig-statistical-process-statistical-process
#| fig-cap: Illustration of the statistical process.
#| fig-alt: Series of blobs forming a cycle, representing information coming from the population to the sample and back to the population.
#| echo: false

knitr::include_graphics("images/Statistical-Process-Statistical-Process.jpg")
```


## Data Storage
Each measurement, or piece of information, you record for a subject is a different __variable__.  

:::{#def-variable}
## Variable
A measurement, or category, describing some aspect of the subject.
:::

In order to conduct analysis, it is best to adhere to "tidy data principles" [@Wickham2014] when storing data.  In brief:

  1. Each column contains a unique variable.
  2. Each record (or row in the data set) corresponds to a different observation of the variable(s).  If each subject is only measured once (a single survey for each subject, for example), each record will correspond to a different subject.  If, on the other hand, each subject is measured multiple times (the same survey is given prior to an appointment and at a specified follow-up period, for example), there may be multiple records which correspond to the same subject, but each record corresponds to a unique observation.
  3. If you have multiple data sets, there should be a variable in the table that allows the various tables to be linked (subject identifier).  For larger more complex studies, for example, you may have one table that has the demographic information of subjects and a separate table which contains the lab results for the subjects.
  4. The first row in the data set should have the names of each variable.
  
The above description eliminates a common method of data storage --- placing different groups in different spreadsheets.  All observations should be stored together.  The first few records of a hypothetical data set are illustrated in @tbl-statistical-process-tidy-data.

```{r}
#| label: tbl-statistical-process-tidy-data
#| tbl-cap: Example of storying data according to "tidy data" principles.  Data is from a hypothetical study.
#| echo: false
 
set.seed(123)

mydat <- infert |>
  mutate(
    `Subject ID` = sample((1001:(1000 + nrow(infert))), replace = FALSE),
    `Treatment Group` = 
       case_match(
         case,
         1 ~ 'Placebo',
         0 ~ 'Active Treatment'),
    age = case_when(
      case == 0 ~ my_scale(age, low = 25, high = 37),
      case == 1 ~ age),
    age = as.integer(round(age)),
    parity = as.integer(parity),
    spontaneous = as.integer(spontaneous)) 

mydat |>
  group_by(`Treatment Group`) |>
  slice(1:6) |>
  ungroup() |>
  select(`Subject ID`,
         Education = education,
         `Age (yrs)` = age,
         Parity = parity,
         `Number of Miscarriages` = spontaneous,
         `Treatment Group`) |>
  mykable()
```

Once your data has been placed in a spreadsheet, it should be kept separate from the analysis.  Any changes to the data should be done using your analysis file so that those changes are clearly documented alongside the analysis.  While it may be easy, it is poor practice to include graphics and numeric summaries in the same spreadsheet as the data.  If you want your data to be _portable_ (easily opened by any spreadsheet or analysis software package), save your data as a comma separated file (CSV).


## Tabular Data Presentation
If you have several variables you want to summarize, this is probably best done using a table.  For example, you may want to summarize the demographics of the subjects in your study across each treatment group.  How a variable is summarized depends on its type.  __Qualitative__ (or __categorical__) variables define a grouping or categorization of a subject (e.g., race, treatment group, etc.).  When summarizing qualitative data, we generally report the number of subjects in each group and the corresponding percentage of the sample. 

:::{#def-categorical-variable}
## Categorical Variable
Also called a "qualitative variable," a measurement on a subject which denotes a grouping or categorization.
:::

__Quantitative__ (or __numeric__) variables are those measurements for which arithmetic makes sense (e.g., heart rate, age).  These variables are generally summarized by reporting both a measure of location and spread; this could be mean and standard deviation or median and interquartile range.  

:::{#def-numeric-variable}
## Numeric Variable
Also called a "quantitative variable," a measurement on a subject which takes on a numeric value _and_ for which ordinary arithmetic makes sense.
:::

If you are not comparing groups of subjects, it is reasonable to report results for the entire sample.  If the goal of your research is to compare groups (such as rural vs. urban residents), we typically summarize data within each group and present the comparisons side by side. @tbl-statistical-process-data-summary summarizes the data from our hypothetical study, allowing the reader to compare the treatment and placebo groups.  Notice that while we might think of the number of miscarriages as being a numeric variable, when there are only a small number of possibilities, we might treat that variable as categorical for the purposes of summarizing it.

```{r}
#| label: tbl-statistical-process-data-summary
#| tbl-cap: Summary of patient characteristics from our hypothetical study.
#| echo: false

mydat |>
  select(
    `Treatment Group`,
    education,
    age,
    parity,
    spontaneous
  ) |>
  gtsummary::tbl_summary(
    by = `Treatment Group`,
    label = list(
      `education` ~ 'Education',
      `age` ~ 'Age',
      `parity` ~ 'Parity',
      `spontaneous` ~ 'Number of Miscarriages'
    ),
    type = list(
      c('education', 'spontaneous') ~ 'categorical',
      c('age', 'parity') ~ 'continuous'
    ),
    statistic = list(
      gtsummary::all_continuous() ~ '{mean} ({sd})',
      gtsummary::all_categorical() ~ '{n} ({p}%)'
    ),
    digits = list(
      gtsummary::all_continuous() ~ 2
    )
  )
```


When reporting numerical summaries within the body of your report, it is good to keep the same format as you adopt in the table; for example, summarizing a qualitative variables with N (%).

Statistics is generally concerned with explaining the variation in a variable, and that is characterized by its __distribution__.  When we summarize a variable, whether numerically or graphically, we are actually summarizing this distribution.

:::{#def-distribution}
## Distribution
The pattern of variability corresponding to a set of values.
:::




## Graphical Data Presentation
As the saying goes, a picture is worth 1000 words.  Each graphic you construct, however, should add value to the story you are telling.  We primarily reserve graphics for conveying a message about our primary __response__.  

:::{#def-response}
## Response Variable
Also called the "outcome," this is the primary variable of interest in the research question; it is the variable we either want to explain or predict.
:::

As with tabular data presentation, our approach to graphical presentation depends on the type of variable being summarized.  For example, while a scatter-plot is well suited for examining the relationship between two quantitative variables, side-by-side box-plots are better suited for examining the relationship between a quantitative response and a categorical predictor.  

:::{.callout-note}
Following best practices in the research community, we recommend the use of a _bar chart_ instead of a _pie chart_ when examining a categorical response.  Bar charts are often less cluttered and more clearly communicate the same information.
:::

@fig-statistical-process-graphics illustrates two graphics (one for a qualitative and one for a quantitative response); again, in practice, your graphics should be driven by your research question.

```{r}
#| label: fig-statistical-process-graphics
#| echo: false
#| fig-cap: Two graphical presentations of data from a hypothetical study, adhering to good graphical practices.
#| fig-alt: Bar chart summarizing distribution of the number of miscarriages next to a set of side-by-side boxplots with raw data overlaid showing the distribution of the patients age across treatment groups.

set.seed(123)

p1 <- ggplot(data = mydat,
             mapping = aes(x = spontaneous,
                           fill = `Treatment Group`)) +
  geom_bar(position = "dodge") +
  labs(y = "Number of Patients",
       x = "Number of Miscarriages",
       fill = NULL) +
  scale_fill_brewer(type = "qual", palette = "Dark2") +
  theme_minimal(14) +
  theme(legend.position = "bottom")

p2 <- ggplot(data = mydat,
             mapping = aes(x = `Treatment Group`,
                           y = age)) +
  geom_boxplot(linewidth = 1.1) +
  geom_jitter(alpha = 0.25, height = 0, width = 0.15) + 
  labs(y = "Age of Patient (yrs)",
       x = NULL) +
  theme_minimal(14)

cowplot::plot_grid(p1, p2, rel_widths = c(0.5, 0.5),
                   nrow = 1, ncol = 2, axis = "b", align = "h")
```

Notice that the left panel of the graphic makes use of bar charts to compare a qualitative variable (number of miscarriages) across a second qualitative variable (treatment group).  The use of color here is important because it brings out additional features that do not appear on the x- or y-axis.  The right panel of the graphic makes use of box-plots (with jitter-plots overlaid) to compare a quantitative variable (age of the patient) across the qualitative variable (treatment group).  One idea worth discussing here is that a graphical summary of a quantitative variable should always portray both _location_ and _spread_.  Notice that in the right panel in @fig-statistical-process-graphics, we see that the ages of patients receiving placebo are comparable (in location) to that of those receiving the active treatment; however, the variability in the ages of patients receiving placebo is much larger compared to those receiving the active treatment.  Compare this to @fig-statistical-process-poor-graphics, which only summarizes location with no sense of spread; while this is a popular default graphic in some software, it does not adequately allow a reader to determine the size of the effect relative to the variability in the data.

```{r}
#| label: fig-statistical-process-poor-graphics
#| echo: false
#| fig-cap: Inappropriate graphical presentation from a hypothetical study as it ignores a sense of variability in the data.
#| fig-alt: Bars used to represent the mean age in different groups.

set.seed(123)

ggplot(data = mydat,
       mapping = aes(x = `Treatment Group`,
                     y = age)) +
  stat_summary(geom = "bar", fun = mean) + 
  geom_label(data = mydat |>
               group_by(`Treatment Group`) |>
               summarise(age = mean(age)),
             mapping = aes(label = round(age, 1))) +
  labs(y = "Average Age of Patient (yrs)",
       x = NULL) +
  theme_minimal(14)
```



## Basic Terminology for Statistical Tests
In some cases, summarizing the data numerically and graphically is sufficient for telling a compelling story.  Often, however, the summaries are accompanied by a statistical analysis.  Regardless of the simplicity (or complexity) of the statistical procedure, there are a few fundamental ideas which are common to all methods.

A __statistic__ (summary of data) is a point estimate of a __parameter__ (corresponding value in the population of interest).  For example, the value `r mydat |> rename(TrtGrp = 'Treatment Group') |> filter(TrtGrp == 'Active Treatment') |> pull(parity) |> mean() |> round(2)` in @tbl-statistical-process-data-summary is the average number of children among those women in the study who received the active treatment; but, it _estimates_ the average number of children among all women in the population who receive the active treatment.

:::{#def-parameter}
## Parameter
Numeric quantity which summarizes the distribution of a variable within the _population_ of interest.  Generally denoted by Greek letters in statistical formulas.
:::

:::{#def-statistic}
## Statistic
Numeric quantity which summarizes the distribution of a variable within the observed _sample_.
:::

Instead of estimating a parameter with this single value, we can estimate the parameter with a __confidence interval__ (a 95% confidence interval is standard practice).  

:::{#def-confidence-interval}
## Confidence Interval
An interval (range of values) estimate of a parameter that incorporates the variability in the statistic.  The process of constructing $k$% confidence intervals results in them containing the parameter of interest in $k$% of _repeated_ studies.  The value of $k$ is called the _confidence level_.
:::

It is important to recognize that the entire interval is our estimate.  In text, we generally report the point estimate with the 95% confidence interval in parentheses.  For example, 

```{r}
#| label: statistical-process-model
#| echo: false

m1.hypothetical <- 
  glm(I(spontaneous>0) ~ `Treatment Group`, 
      family = "binomial", data = mydat)
```


  > The probability of a miscarriage is `r display_est(m1.hypothetical, '(Intercept)', trans = function(u) exp(u)/(1+exp(u)))` (95% CI: `r display_ci(m1.hypothetical, '(Intercept)', trans = function(u) exp(u)/(1+exp(u)))`) for women given the active treatment.

There are several common misinterpretations of a confidence interval; generally, these do not enter the literature because we avoid interpreting the interval directly and simply state it and discuss its implications (as above).  For completeness, however, it is best to think of a confidence interval as giving all the reasonable values of the parameter based on the data observed.

While confidence intervals estimate an effect, a __p-value__ quantifies the amount of evidence in the data against the lack of an effect.  

:::{#def-pvalue}
## P-Value
The probability, assuming the null hypothesis is true, that we would observe a statistic, from sampling variability alone, as extreme or more so as that observed in our sample.  This quantifies the strength of evidence against the null hypothesis.  Smaller values indicate stronger evidence.
:::

We generally report a p-value to 3 decimal places (with values less than 0.001 being written as "< 0.001").  It is best to state p-values alongside the conclusion.  For example,

  > There is strong evidence (`r display_pval(m1.hypothetical, 'Treatment GroupPlacebo')`) that the active treatment reduces the risk of a miscarriage.

:::{.callout-caution}
There are two very important things to keep in mind when examining a p-value:

  1. A small p-value does not imply the effect is clinically relevant/important.  It simply indicates that we are able to statistically discern an effect/difference is present.
  2. A large p-value does not imply there is no effect/difference.  It simply indicates that we cannot statistically discern the presence of an effect/difference.
:::

For these reasons, a p-value should always be accompanied by either a confidence interval (preferred when possible) or a point estimate of the effect to allow readers to determine if the impact is clinically relevant.

When interpreting statistical results, the design of the study plays a role.  In particular, we can only conclude a causal relationship when the data is from a __randomized clinical trial__.  When your data is from an __observational study__, any group comparisons are subject to __confounding__.

:::{#def-randomized-clinical-trial}
## Randomized Clinical Trial
Also called a "controlled experiment," a study in which each participant is randomly assigned to one of the groups being compared in the study.
:::

:::{#def-observational-study}
## Observational Study
A study in which each participant "self-selects" into one of groups being compared in the study. The phrase "self-selects" is used very loosely here and can include studies in which the groups are defined by an inherent characteristic, the groups are determined according to a non-random mechanism, and each participant chooses the group to which they belong.
:::

:::{#def-confounding}
## Confounding
When the effect of a variable on the response is mis-represented due to the presence of a third, potentially unobserved, variable known as a confounder.
:::

:::{#exm-dental-health}
## Dental Health and Cardiovascular Disease
It has been suggested that brushing your teeth twice a day for at least two minutes may lower the risk of cardiovascular diseases[^heart].  

However, most of these results are from large surveys, which are observational studies.  It is quite plausible that those who take excellent care of their teeth tend to be health-conscious individuals, and health-conscious individuals are more likely to have healthy diets and exercise regularly, both of which decrease the risk of cardiovascular diseases.  
:::

In @exm-dental-health, being health-conscious is a confounder because it is associated with _both_ the factor under study (brushing behavior) _and_ the outcome of interest (cardiovascular disease); see @fig-statistical-process-confounding.  In order to establish a causal link between brushing and the risk of cardiovascular disease, we could conduct a clinical trial in which we randomize patients to a brushing routine and then track their long-term cardiovascular health; in this design, the link between the confounder and the treatment group is broken, allowing us to make a causal conclusion.  While clinical trials allow for causal conclusions, they are not always feasible or practical; observational studies allow us to add to the body of knowledge in such situations.  There are some methods for addressing confounding in observational studies through statistical analysis, but such methods often require a large sample and more advanced methodology.

```{r}
#| label: fig-statistical-process-confounding
#| echo: false
#| fig-cap: Illustration of confounding in observational studies.
#| fig-alt: Three circles showing a directional diagram; one circle represents the predictor, another the confounder, and the last the response.  The confounder is connected to both the predictor and the response.

knitr::include_graphics("images/Statistical-Process-Confounding.jpg")
```


## A Note on Codebooks
A dataset on its own is meaningless if you cannot understand what the values represent.  _Before_ you access a dataset, you should always review any available __codebook__.

:::{#def-codebook}
## Codebook
Also called a "data dictionary," a codebook provides complete information regarding the variables contained within a dataset.
:::

Some codebooks are excellent, with detailed descriptions of how the variables were collected and appropriate units.  Other codebooks give only an indication of what each variable represents.  Whenever you are working with previously collected data, reviewing a codebook is the first step; and, you should be prepared to revisit the codebook often throughout an analysis.  When you are collecting your own dataset, constructing a codebook is essential for others to make use of your data.




[^heart]: [https://www.heart.org/en/news/2018/11/07/bad-tooth-brushing-habits-tied-to-higher-heart-risk](https://www.heart.org/en/news/2018/11/07/bad-tooth-brushing-habits-tied-to-higher-heart-risk)
